{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb57116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c228d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================= KONFIGURASI =================\n",
    "DATASET_FILE = '/home/ahmad/Documents/Prata/Code/ML/gesture-ml-project_V1/src/dataset/eye_dataset_wheelchair_continuous.csv'\n",
    "MODEL_FILENAME = 'wheelchair_gaze_model.h5'\n",
    "SCALER_FILENAME = 'gaze_scaler.pkl'\n",
    "ENCODER_FILENAME = 'label_encoder.pkl'\n",
    "\n",
    "# Fitur yang digunakan\n",
    "FEATURES = ['dx_rel', 'dy_rel', 'ear_left', 'ear_right']\n",
    "\n",
    "# Sequence Length (Jendela Waktu)\n",
    "SEQUENCE_LENGTH = 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================= 1. LOAD & PREPROCESS DATA =================\n",
    "\n",
    "def load_data(filepath):\n",
    "    print(f\"Loading dataset: {filepath}...\")\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File {filepath} tidak ditemukan!\")\n",
    "        \n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Filter noise jarak\n",
    "    df = df[(df['dist_cm'] > 20) & (df['dist_cm'] < 80)]\n",
    "    \n",
    "    print(f\"Total data bersih: {len(df)} baris\")\n",
    "    print(f\"Distribusi Label:\\n{df['label'].value_counts()}\")\n",
    "    return df\n",
    "\n",
    "def create_sequences(data, labels, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        # Cek konsistensi label dalam satu window\n",
    "        label_window = labels.iloc[i:(i + time_steps)]\n",
    "        if label_window.nunique() == 1: \n",
    "            v = data.iloc[i:(i + time_steps)].values\n",
    "            Xs.append(v)\n",
    "            ys.append(label_window.iloc[-1])\n",
    "            \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Main Process\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df = load_data(DATASET_FILE)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # A. Encoding Label\n",
    "    encoder = LabelEncoder()\n",
    "    df['label_encoded'] = encoder.fit_transform(df['label'])\n",
    "    labels_map = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "    print(f\"Label Mapping: {labels_map}\")\n",
    "\n",
    "    # B. Normalisasi (Scaling)\n",
    "    scaler = MinMaxScaler()\n",
    "    df[FEATURES] = scaler.fit_transform(df[FEATURES])\n",
    "\n",
    "    # C. Membuat Sequence\n",
    "    print(\"Membuat Sequence Data...\")\n",
    "    X, y = create_sequences(df[FEATURES], df['label_encoded'], SEQUENCE_LENGTH)\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        print(\"ERROR: Data tidak cukup untuk membuat sequence.\")\n",
    "        exit()\n",
    "\n",
    "    # D. One-Hot Encoding\n",
    "    y_cat = to_categorical(y)\n",
    "\n",
    "    # E. SPLIT DATA 3-WAY (Train 70%, Val 15%, Test 15%)\n",
    "    # Langkah 1: Pisahkan Train (70%) dan Sisa (30%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y_cat, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Langkah 2: Pisahkan Sisa menjadi Val (50% dari sisa) dan Test (50% dari sisa)\n",
    "    # 0.5 * 0.3 = 0.15 (15% total)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42, stratify=np.argmax(y_temp, axis=1)\n",
    "    )\n",
    "\n",
    "    print(f\"Data Training   : {X_train.shape[0]} samples\")\n",
    "    print(f\"Data Validation : {X_val.shape[0]} samples\")\n",
    "    print(f\"Data Testing    : {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # ================= 2. MEMBANGUN MODEL BiLSTM =================\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.3)) \n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(y_cat.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # ================= 3. TRAINING =================\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        MODEL_FILENAME, \n",
    "        monitor='val_loss', \n",
    "        verbose=1, \n",
    "        save_best_only=True, \n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    print(\"\\nMulai Training...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val), # Menggunakan data validasi eksplisit\n",
    "        callbacks=[checkpoint, early_stop],\n",
    "        verbose=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca24811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # ================= 4. EVALUASI COMPREHENSIVE =================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"EVALUASI MODEL (DATA TESTING)\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    # Prediksi Data Test (Data yang belum pernah dilihat model)\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # 1. Metrics Dasar\n",
    "    acc = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    prec = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "    rec = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "    print(f\"\\nOverall Accuracy  : {acc*100:.2f}%\")\n",
    "    print(f\"Weighted Precision: {prec*100:.2f}%\")\n",
    "    print(f\"Weighted Recall   : {rec*100:.2f}%\")\n",
    "    print(f\"Weighted F1-Score : {f1*100:.2f}%\")\n",
    "\n",
    "    # 2. Classification Report (Detail per Label)\n",
    "    print(\"\\nDetail Per Kelas:\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=encoder.classes_))\n",
    "\n",
    "    # 3. Confusion Matrix Visualization\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # Simpan Scaler & Encoder\n",
    "    joblib.dump(scaler, SCALER_FILENAME)\n",
    "    joblib.dump(encoder, ENCODER_FILENAME)\n",
    "    print(\"\\n[INFO] Scaler & Encoder disimpan.\")\n",
    "\n",
    "    # Plotting Evaluasi\n",
    "    try:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Plot A: Accuracy & Loss\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "        plt.title('Training History')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot B: Confusion Matrix\n",
    "        plt.subplot(1, 3, 2)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "\n",
    "        # Plot C: Bar Chart Metrics\n",
    "        plt.subplot(1, 3, 3)\n",
    "        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "        values = [acc, prec, rec, f1]\n",
    "        bars = plt.bar(metrics, values, color=['#4285F4', '#34A853', '#FBBC05', '#EA4335'])\n",
    "        plt.title('Model Performance Metrics')\n",
    "        plt.ylim(0, 1.1)\n",
    "        # Menambah label angka di atas bar\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                     f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal menampilkan plot: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre_jetson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
